{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/openai/CLIP\n",
    "!git clone https://github.com/CompVis/taming-transformers\n",
    "!pip install ftfy regex tqdm omegaconf pytorch-lightning einops transformers\n",
    "!pip install -e ./taming-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -OL --http1.1 'https://the-eye.eu/public/AI/models/cond_transformer_2/transformer_cond_2_00003_090000_modelonly.pth'\n",
    "!curl -L 'https://heibox.uni-heidelberg.de/d/a7530b09fed84f80a887/files/?p=%2Fconfigs%2Fmodel.yaml&dl=1' > vqgan_imagenet_f16_16384.yaml\n",
    "!curl -L 'https://heibox.uni-heidelberg.de/d/a7530b09fed84f80a887/files/?p=%2Fckpts%2Flast.ckpt&dl=1' > vqgan_imagenet_f16_16384.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from IPython import display\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as TF\n",
    "from transformers import top_k_top_p_filtering\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "sys.path.append('./taming-transformers')\n",
    "\n",
    "from CLIP import clip\n",
    "from taming.models import vqgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalTransformerEncoder(nn.TransformerEncoder):\n",
    "    def forward(self, src, mask=None, src_key_padding_mask=None, cache=None):\n",
    "        output = src\n",
    "\n",
    "        if self.training:\n",
    "            if cache is not None:\n",
    "                raise ValueError(\"cache parameter should be None in training mode\")\n",
    "            for mod in self.layers:\n",
    "                output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "            if self.norm is not None:\n",
    "                output = self.norm(output)\n",
    "\n",
    "            return output\n",
    "\n",
    "        new_token_cache = []\n",
    "        compute_len = src.shape[0]\n",
    "        if cache is not None:\n",
    "            compute_len -= cache.shape[1]\n",
    "        for i, mod in enumerate(self.layers):\n",
    "            output = mod(output, compute_len=compute_len)\n",
    "            new_token_cache.append(output)\n",
    "            if cache is not None:\n",
    "                output = torch.cat([cache[i], output], dim=0)\n",
    "\n",
    "        if cache is not None:\n",
    "            new_cache = torch.cat([cache, torch.stack(new_token_cache, dim=0)], dim=1)\n",
    "        else:\n",
    "            new_cache = torch.stack(new_token_cache, dim=0)\n",
    "\n",
    "        return output, new_cache\n",
    "\n",
    "\n",
    "class CausalTransformerEncoderLayer(nn.TransformerEncoderLayer):\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None, compute_len=None):\n",
    "        if self.training:\n",
    "            return super().forward(src, src_mask, src_key_padding_mask)\n",
    "\n",
    "        if compute_len is None:\n",
    "            src_last_tok = src\n",
    "        else:\n",
    "            src_last_tok = src[-compute_len:, :, :]\n",
    "\n",
    "        attn_mask = src_mask if compute_len > 1 else None\n",
    "        tmp_src = self.self_attn(src_last_tok, src, src, attn_mask=attn_mask,\n",
    "                                 key_padding_mask=src_key_padding_mask)[0]\n",
    "        src_last_tok = src_last_tok + self.dropout1(tmp_src)\n",
    "        src_last_tok = self.norm1(src_last_tok)\n",
    "\n",
    "        tmp_src = self.linear2(self.dropout(self.activation(self.linear1(src_last_tok))))\n",
    "        src_last_tok = src_last_tok + self.dropout2(tmp_src)\n",
    "        src_last_tok = self.norm2(src_last_tok)\n",
    "        return src_last_tok\n",
    "\n",
    "\n",
    "class CLIPToImageTransformer(nn.Module):\n",
    "    def __init__(self, clip_dim, seq_len, n_toks):\n",
    "        super().__init__()\n",
    "        self.clip_dim = clip_dim\n",
    "        d_model = 1024\n",
    "        self.clip_in_proj = nn.Linear(clip_dim, d_model, bias=False)\n",
    "        self.clip_score_in_proj = nn.Linear(1, d_model, bias=False)\n",
    "        self.in_embed = nn.Embedding(n_toks, d_model)\n",
    "        self.out_proj = nn.Linear(d_model, n_toks)\n",
    "        layer = CausalTransformerEncoderLayer(d_model, d_model // 64, d_model * 4,\n",
    "                                              dropout=0, activation='gelu')\n",
    "        self.encoder = CausalTransformerEncoder(layer, 24)\n",
    "        self.pos_emb = nn.Parameter(torch.zeros([seq_len + 1, d_model]))\n",
    "        self.register_buffer('mask', self._generate_causal_mask(seq_len + 1), persistent=False)\n",
    "\n",
    "    @staticmethod\n",
    "    def _generate_causal_mask(size):\n",
    "        mask = (torch.triu(torch.ones([size, size])) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0))\n",
    "        mask[0, 1] = 0\n",
    "        return mask\n",
    "\n",
    "    def forward(self, clip_embed, clip_score, input=None, cache=None):\n",
    "        if input is None:\n",
    "            input = torch.zeros([len(clip_embed), 0], dtype=torch.long, device=clip_embed.device)\n",
    "        clip_embed_proj = self.clip_in_proj(F.normalize(clip_embed, dim=1) * self.clip_dim**0.5)\n",
    "        clip_score_proj = self.clip_score_in_proj(clip_score)\n",
    "        embed = torch.cat([clip_embed_proj.unsqueeze(0),\n",
    "                           clip_score_proj.unsqueeze(0),\n",
    "                           self.in_embed(input.T)])\n",
    "        embed_plus_pos = embed + self.pos_emb[:len(embed)].unsqueeze(1)\n",
    "        mask = self.mask[:len(embed), :len(embed)]\n",
    "        out, cache = self.encoder(embed_plus_pos, mask, cache=cache)\n",
    "        return self.out_proj(out[1:]).transpose(0, 1), cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Parameters\n",
    "import argparse\n",
    "\n",
    "directory = \"CLIP\" #@param {type:\"string\"}\n",
    "keyword = \"the princess is in another castle\" #@param {type:\"string\"}\n",
    "loops = 16 #@param {type:\"number\"}\n",
    "batch_size = 16 #@param {type:\"number\"}\n",
    "clip_score = 0.475 #@param {type:\"number\"}\n",
    "half = True #@param {type:\"boolean\"}\n",
    "k = 8 #@param {type:\"number\"}\n",
    "n = 128 #@param {type:\"number\"}\n",
    "seed = -1 #@param {type:\"number\"}\n",
    "temperature = 1. #@param {type:\"number\"}\n",
    "top_k = 0 #@param {type:\"number\"}\n",
    "top_p = 0.95 #@param {type:\"number\"}\n",
    "\n",
    "styles = [\"8k resolution\",\"pencil sketch\",\"8K 3D\",\"creative commons attribution\",\"deviantart\",\"CryEngine\",\"concept art\",\"photoillustration\",\"pixiv\",\"flickr\",\"ArtStation HD\",\n",
    "          \"Behance HD\",\"HDR\",\"anime\",\"filmic\",\"Stock Photo\",\"Ambient occlusion\",\"Global illumination\",\"Chalk art\",\"Low poly\",\"Booru\",\"Polycount\",\"Acrylic art\",\"Hyperrealism\",\n",
    "          \"Zbrush central\",\"Rendered in Cinema4D\",\"Rendered in Maya\",\"Photo taken with Nikon D750\",\"Tilt shift\",\"Mixed Media\",\"Depth of Field\",\"DSLR\",\"Detailed painting\",\n",
    "          \"Volumetric lighting\",\"Storybook illustration\",\"Unsplash contest winner\",\"#vfxfriday\",\"Ultrafine detail\",\"20 megapixels\",\"Photo taken with Fugifilm Superia\",\n",
    "          \"Photo taken with Ektachrome\",\"matte painting\",\"reimagined by industrial light and magic\",\"Watercolor\",\"CGSociety\",\"child's drawing\",\"marble sculpture\",\"airbrush art\",\n",
    "          \"renaissance painting\",\"Velvia\",\"Provia\",\"Photo taken with Provia\",\"prerendered graphics\",\"criterion collection\",\"dye transfer\",\"stipple\",\"Parallax\",\"Bryce 3D\",\"Terragen\",\n",
    "          \"Bokeh\",\"1990's, 1995\",\"1980's, 1985\",\"1970's, 1975\",\"1960's, 1965\",\"1950's, 1955\",\"1940's, 1945\",\"1930's, 1935\",\"1920's, 1925\",\"charcoal drawing\",\"Commission for\",\n",
    "          \"flat shading\",\"ink drawing\",\"artwork\",\"oil on canvas\",\"macro photography\",\"hall of mirrors\",\"polished\",\"sunrays shine upon it\",\"aftereffects\",\"iridescent\",\"#film\",\n",
    "          \"datamosh\",\"(1962) directed by cinematography by\",\"holographic\",\"Dutch golden age\",\"digitally enhanced\",\"National Geographic photo\",\"matte background\",\"Art on Instagram\",\n",
    "          \"#myportfolio\",\"bokeh\",\"digital illustartion\",\"stock photo\",\"speedpainting\",\"colorized\",\"detailed\",\"psychedelic\",\"wavy\",\"groovy\",\"movie poster\",\"pop art\",\"made of beans and yarn\",\n",
    "          \"made of feathers\",\"made of crystals\",\"made of liquid metal\",\"made of glass\",\"made of cardboard\",\"made of vines\",\"made of cheese\",\"made of flowers\",\"made of insects\",\"made of mist\",\n",
    "          \"made of rubber\",\"made of plastic\",\"made of chrome\",\"made of wire\",\"made of trash\",\"made of wrought iron\",\"made of all of the above\",\"woodcut\",\"American propaganda\",\"Soviet propaganda\",\n",
    "          \"PS1 Graphics\",\"Sega Genesis Graphics\",\"Atari 2600 Graphics\",\"Fine art\",\"HD mod\",\"Photorealistic\",\"Poster Art\",\"Constructivism\",\"Brutalism\",\"pre-Raphaelite\",\"Impressionism\",\n",
    "          \"lowbrow\",\"RTX on\",\"chiaroscuro\",\"Egyptian Art\",\"masterpiece\",\"Fauvism\",\"Shot on 70mm\",\"Art Deco\",\"Picasso\",\"Da Vinci\",\"Academic Art\",\"Children's Book\",\"Photocollage\",\n",
    "          \"Cubism\",\"Surrealist\",\"THX Sound\",\"ZBrush\",\"Panorama\",\"Smooth\",\"1970's Album Art\",\"DC Comics\",\"Marvel Comics\",\"Ukiyo-e\",\"Flemish Baroque\",\"vray tracing\",\"pixel perfect\",\n",
    "          \"quantum wavetracing\",\"Zbrush central contest winner\",\"ISO 200\",\"Bob Ross\",\"32k HUHD\",\"Photocopy\",\"DeviantArt HD\",\"Tri-X 400 TX\",\"Trending on artstation\",\"Featured on artstation\",\n",
    "          \"Artstation HQ\",\"Ultra HD\",\"high quality photo\",\"instax\",\"Illford HPS\",\"Lomo\",\"Matte drawing\",\"matte photo\",\"glowing neon\",\"Xbox 360 graphics\",\"Flickering light\",\"lens flare\",\n",
    "          \"J.J. Abrams Movie\",\"Playstation 5 screenshot\",\"Kodak Gold 200\",\"by Edward Hopper\",\"rough\",\"maximalist\",\"minimalist\",\"Kodak Ektar\",\"Polaroid\",\"Kodak Potra\",\"geometric\",\"cluttered\",\n",
    "          \"Rocaco\",\"SSAO\",\"destructive\",\"by James Gurney\",\"by Thomas Kinkade\",\"by Vincent DiFate\", \"by Jim Burns\",\"2D Game Art\", \"Windows XP\", \"Y2K aesthetic\",\"#screenshotsaturday\",\"seapunk\",\n",
    "          \"Vaporwave\",\"by Ilya Kuvshinov\",\"by Paul Cezanne\",\"by Henry Moore\",\"by Odilon Redon\",\"by Beksinski\", \"by Dali\", \"by Van Gogh\", \"by Geiger\", \"by Monet\", \"by Kimlit\", \"by Katsuhiro Otomo\",\n",
    "          \"by Miguel Angel\", \"by Joaquin Sorolla\", \"Cave Painting\", \"Moebius\",\n",
    "          \"by M.C. Escher\", \"by Michelangelo Caravaggio\", \"by Claude Monet\", \"by Edgar Degas\", \"by Bob Ross\", \"by Bill Watterson\", \"Brutalism\", \"Vienna Sucession\",\n",
    "          \"rendered in Unreal Engine\", \"rendered in POV Ray\", \"Picasso\", \"Pop Art\", \"Modern art\", \"Raphael\", \"impressionism\", \"Andy Warhol\", \"oil paints\", \n",
    "          \"watercolours\", \"comic\", \"fisheye\", \"German Romanticism\", \"Indian Art\", \"Impressionism\", \"Luminism\", \"Pointillism\", \"postimpressionism\", \"Jim Davis\",\n",
    "          \"Isometric\", \"Lineart\", \"Lofi\", \"Lowpoly\", \"Photoshop\", \"Pixel art\", \"Vector Art\", \"Voxel Art\", \"Clay\" ,\"collage\", \"embroidery\", \"Graphite Drawing\", \"ink drawing\",\n",
    "          \"detailed oil painting\", \"stained glass\", \"tempera\", \"cell shading\", \"visual novel\", \"electric colors\", \"photorealistic\", \"hyperrealistic\", \"shaders\",\n",
    "          \"diorama\", \"depth of field\", \"ray tracing\", \"global illumination\", \"iridicent\", \"trending on artstation\",\n",
    "          \"vibrant\", \"Star Wars\", \"Raiders of the Lost Ark\", \"The Lord of the Rings\", \"Interstellar\", \"Mad Max Fury Road\", \"The Wizard of Oz\",\n",
    "          \"Akira\", \"Inception\", \"a Pixar movie\", \"the Avatar movie\", \"the 300 movie\", \"a Wes Anderson movie\", \"Blade Runner\", \"The Fifth Element\"]\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    prompt=\"\",\n",
    "    batch_size=batch_size,\n",
    "    clip_score=clip_score,\n",
    "    half=half,\n",
    "    k=k,\n",
    "    n=n,\n",
    "    output=\"\",\n",
    "    seed=seed,\n",
    "    temperature=temperature,\n",
    "    top_k=top_k,\n",
    "    top_p=top_p,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for i in range(loops):\n",
    "  chosen_style = random.choice(styles)\n",
    "\n",
    "  prompt=keyword + \" \" + chosen_style\n",
    "  print(prompt)\n",
    "  args.prompt=prompt\n",
    "  args.output=prompt\n",
    "\n",
    "  device = torch.device('cuda:0')\n",
    "  dtype = torch.half if args.half else torch.float\n",
    "\n",
    "  perceptor = clip.load('ViT-B/32', jit=False)[0].to(device).eval().requires_grad_(False)\n",
    "  normalize = transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "                                  std=[0.26862954, 0.26130258, 0.27577711])\n",
    "  vqgan_config = OmegaConf.load('vqgan_imagenet_f16_16384.yaml')\n",
    "  vqgan_model = vqgan.VQModel(**vqgan_config.model.params).to(device)\n",
    "  vqgan_model.eval().requires_grad_(False)\n",
    "  vqgan_model.init_from_ckpt('vqgan_imagenet_f16_16384.ckpt')\n",
    "  del vqgan_model.loss\n",
    "\n",
    "  clip_dim = perceptor.visual.output_dim\n",
    "  clip_input_res = perceptor.visual.input_resolution\n",
    "  e_dim = vqgan_model.quantize.e_dim\n",
    "  f = 2**(vqgan_model.decoder.num_resolutions - 1)\n",
    "  n_toks = vqgan_model.quantize.n_e\n",
    "  size_x, size_y = 384, 384\n",
    "  toks_x, toks_y = size_x // f, size_y // f\n",
    "\n",
    "  model = CLIPToImageTransformer(clip_dim, toks_y * toks_x, n_toks)\n",
    "  ckpt = torch.load('transformer_cond_2_00003_090000_modelonly.pth', map_location='cpu')\n",
    "  model.load_state_dict(ckpt['model'])\n",
    "  del ckpt\n",
    "  model = model.to(device, dtype).eval().requires_grad_(False)\n",
    "\n",
    "  if args.seed is not None:\n",
    "      torch.manual_seed(args.seed)\n",
    "\n",
    "  text_embed = perceptor.encode_text(clip.tokenize(args.prompt).to(device)).to(dtype)\n",
    "  text_embed = text_embed.repeat([args.n, 1])\n",
    "  clip_score = torch.ones([text_embed.shape[0], 1], device=device, dtype=dtype) * args.clip_score\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def sample(clip_embed, clip_score, temperature=1., top_k=0, top_p=1.):\n",
    "      tokens = torch.zeros([len(clip_embed), 0], dtype=torch.long, device=device)\n",
    "      cache = None\n",
    "      for i in trange(toks_y * toks_x, leave=False):\n",
    "          logits, cache = model(clip_embed, clip_score, tokens, cache=cache)\n",
    "          logits = logits[:, -1] / temperature\n",
    "          logits = top_k_top_p_filtering(logits, top_k, top_p)\n",
    "          next_token = logits.softmax(1).multinomial(1)\n",
    "          tokens = torch.cat([tokens, next_token], dim=1)\n",
    "      return tokens\n",
    "\n",
    "  def decode(tokens):\n",
    "      z = vqgan_model.quantize.embedding(tokens).view([-1, toks_y, toks_x, e_dim]).movedim(3, 1)\n",
    "      return vqgan_model.decode(z).add(1).div(2).clamp(0, 1)\n",
    "\n",
    "  try:\n",
    "      out_lst, sim_lst = [], []\n",
    "      for i in trange(0, len(text_embed), args.batch_size):\n",
    "          tokens = sample(text_embed[i:i+args.batch_size], clip_score[i:i+args.batch_size],\n",
    "                          temperature=args.temperature, top_k=args.top_k, top_p=args.top_p)\n",
    "          out = decode(tokens)\n",
    "          out_lst.append(out)\n",
    "          out_for_clip = F.interpolate(out, (clip_input_res, clip_input_res),\n",
    "                                      mode='bilinear', align_corners=False)\n",
    "          image_embed = perceptor.encode_image(normalize(out_for_clip)).to(dtype)\n",
    "          sim = torch.cosine_similarity(text_embed[i:i+args.batch_size], image_embed)\n",
    "          sim_lst.append(sim)\n",
    "      out = torch.cat(out_lst)\n",
    "      sim = torch.cat(sim_lst)\n",
    "      best_values, best_indices = sim.topk(min(args.k, args.n))\n",
    "      for i, index in enumerate(best_indices):\n",
    "          filename = args.output + f'_{i:03}.png'\n",
    "          TF.to_pil_image(out[index]).save(filename)\n",
    "          print(f'Actual CLIP score for output {i}: {best_values[i].item():g}')\n",
    "          display.display(display.Image(filename))\n",
    "  except KeyboardInterrupt:\n",
    "      pass\n",
    "\n",
    "\n",
    "  # Save off the result\n",
    "\n",
    "  !echo saving off $directory/$keyword/$chosen_style\n",
    "  !echo \n",
    "  !mkdir -p \"/content/drive/MyDrive/$directory/$keyword\"\n",
    "  !mv *.png \"/content/drive/MyDrive/$directory/$keyword/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-worship",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
